{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "### Using Selenium, this notebook initializes a zombie web browser to scrape images from Instagram's latest posts. First it navigates to a hashtag's page and grabs links to a certain number of posts, then it visits each post and grabs its image, its hashtags, and a few other pieces of information such as a direct link to the post. All of this data is then saved directly into the `data` and `metadata` folders. \n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy versions below 1.17 may be incompatible with some other \n",
    "# packages, so you may need to replace your current version with \n",
    "# an earlier one in order to run this notebook as-is. \n",
    "# !pip uninstall numpy --yes\n",
    "# !pip install \"numpy<1.17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from selenium.webdriver import Chrome, Firefox\n",
    "#from functions import scrape_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **If you want to scrape your own hashtags,** simply add them to the list, choose how many you want to be scraped, and run the remaining cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE:\n",
    "hashtags = [\"food\", \"animals\", \"selfie\", \"cars\", \"fitness\", \"babies\", \"nature\", \"architecture\"]\n",
    "\n",
    "# Your own hashtags here:\n",
    "#hashtags = [\"selfie\"]\n",
    "\n",
    "# How many hashtags to scrape:\n",
    "num_to_scrape = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our data and metadata folders exist before we start scraping\n",
    "folder_names = [\"data\", \"metadata\"]\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        os.mkdir(folder_name)\n",
    "    except OSError:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from random import random\n",
    "from selenium.webdriver import Chrome, Firefox\n",
    "from urllib.request import urlretrieve\n",
    "from uuid import uuid4\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "global_links = []\n",
    "global_images = []\n",
    "\n",
    "def get_posts(hashtag, n, browser):\n",
    "    \"\"\"With the input of an account page, scrape the n most recent posts urls\"\"\"\n",
    "    url = f\"https://www.instagram.com/explore/tags/{hashtag}/\"\n",
    "    browser.get(url)\n",
    "    post = \"https://www.instagram.com/p/\"\n",
    "    post_links = []\n",
    "    images = []\n",
    "    while len(post_links) < n or len(images) < n:\n",
    "\n",
    "        img_src = [\n",
    "            img.get_attribute(\"src\")\n",
    "            for img in browser.find_elements_by_css_selector(\"article img\")\n",
    "        ]\n",
    "        links = [\n",
    "            a.get_attribute(\"href\") for a in browser.find_elements_by_tag_name(\"a\")\n",
    "        ]\n",
    "\n",
    "        for link in links:\n",
    "            if post in link and link not in global_links and link not in post_links and len(post_links) < n:\n",
    "                post_links.append(link)\n",
    "                global_links.append(link)\n",
    "\n",
    "        for image in img_src:\n",
    "            if image not in images and image not in global_images and len(images) < n:\n",
    "                images.append(image)\n",
    "                global_images.append(image)\n",
    "\n",
    "        scroll_down = \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "        browser.execute_script(scroll_down)\n",
    "        time.sleep(1 + (random() * 5))\n",
    "\n",
    "    return [\n",
    "        {\"post_link\": post_links[i], \"image\": images[i], \"search_hashtag\": hashtag}\n",
    "        for i in range(len(post_links))\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_hashtags(url, browser):\n",
    "    \"\"\"Return a list of hashtags found in all post's comments\"\"\"\n",
    "    browser.get(url)\n",
    "    comments_html = browser.find_elements_by_css_selector(\"span\")\n",
    "    all_hashtags = []\n",
    "    errors = []\n",
    "\n",
    "    for comment in comments_html:\n",
    "        hashtags = re.findall(\"#[A-Za-z]+\", comment.text)\n",
    "        if len(hashtags) > 0:\n",
    "            all_hashtags.extend(hashtags)\n",
    "        \n",
    "    return list(set(all_hashtags))\n",
    "\n",
    "\n",
    "def get_image(url, hashtag):\n",
    "    \"\"\"Download image from given url and return it's name\"\"\"\n",
    "    uuid = uuid4()\n",
    "    urlretrieve(url, f\"data/{hashtag}/{uuid}.jpg\")\n",
    "    name = f\"{uuid}.jpg\"\n",
    "    return name\n",
    "\n",
    "\n",
    "def scrape_data(hashtags, n, delay=5):\n",
    "    \"\"\"\n",
    "    Download n images and return a dictionary with their metadata.\n",
    "    \"\"\"\n",
    "    browser = Firefox()\n",
    "    \n",
    "    #print(hashtags)\n",
    "    main_posts = []\n",
    "    \n",
    "    for hashtag in hashtags:\n",
    "        global_links = []\n",
    "        global_images = []\n",
    "        h_tags = []\n",
    "        count = 0\n",
    "        try:\n",
    "            os.mkdir(f\"data/{hashtag}\")\n",
    "        except OSError:\n",
    "            pass # We probably tried to make something that already exists\n",
    "            while(count < n):\n",
    "                try:\n",
    "                    print(count)\n",
    "                    posts = get_posts(hashtag, n, browser)\n",
    "                    for post in posts:\n",
    "                        h_tags = get_hashtags(post[\"post_link\"], browser)\n",
    "                        time.sleep(random() * delay)\n",
    "                        if(len(h_tags) > 0):\n",
    "                            post[\"hashtags\"] = h_tags\n",
    "                            time.sleep(random() * delay)\n",
    "                            post[\"image_local_name\"] = get_image(post[\"image\"], hashtag)\n",
    "                            time.sleep(random() * delay)\n",
    "                            main_posts.append(post)\n",
    "                            h_tags = []\n",
    "                            count = count + 1\n",
    "\n",
    "                    new_hashtag_metadata = main_posts\n",
    "                except Exception as e: \n",
    "                    print(e)\n",
    "                    new_hashtag_metadata = main_posts\n",
    "\n",
    "\n",
    "                #NOTE TO SELF: transferred code begins here\n",
    "                if os.path.exists(f\"metadata/{hashtag}.json\"):\n",
    "                    # We already have metadata for this hashtag, add to it\n",
    "                    with open(f\"metadata/{hashtag}.json\", \"r\") as f:\n",
    "                        hashtag_metadata = json.load(f)\n",
    "                        hashtag_metadata += new_hashtag_metadata\n",
    "                else:\n",
    "                    # We don't have metadata for this hashtag yet, initialize it\n",
    "                    hashtag_metadata = new_hashtag_metadata\n",
    "\n",
    "                with open(f\"metadata/{hashtag}.json\", \"w\") as f:\n",
    "                    json.dump(hashtag_metadata, f)\n",
    "\n",
    "\n",
    "def prepare_image(img_path, height=160, width=160, where='s3'):\n",
    "    \"\"\"Downsample and scale image to prepare it for neural network\"\"\"\n",
    "    if where=='s3':\n",
    "        img = fetch_image_from_s3_to_array('instagram-images-mod4', img_path)\n",
    "    elif where == 'local':\n",
    "    # If the image is stored locally:\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_image(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/127.5) - 1\n",
    "    img = tf.image.resize(img, (height, width))\n",
    "    # Reshape grayscale images to match dimensions of color images\n",
    "    if img.shape != (160, 160, 3):\n",
    "        img = tf.concat([img, img, img], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_features(image, neural_network):\n",
    "    \"\"\"Return a vector of 1280 deep features for image.\"\"\"\n",
    "    image_np = image.numpy()\n",
    "    images_np = np.expand_dims(image_np, axis=0)\n",
    "    deep_features = neural_network.predict(images_np)[0]\n",
    "    return deep_features\n",
    "\n",
    "\n",
    "def upload_files_to_s3(\n",
    "    dir_path, hashtag, bucket_name\n",
    "):  #ex. dir_path: 'data/cars/' ; hashtag: 'travel'\n",
    "    \"\"\"Upload files from the folder to S3 bucket name: 'instagram-images-mod4' to a seperate folder with hashtag name, \n",
    "    and make a list of images filenames stored in local directory\"\"\"\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(dir_path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "\n",
    "    for name in f:\n",
    "        source = dir_path + name\n",
    "        bucket = bucket_name\n",
    "        destination = hashtag + \"/\" + name\n",
    "        s3.meta.client.upload_file(source, bucket, destination)\n",
    "\n",
    "\n",
    "def fetch_image_from_s3_to_array(bucket, key):\n",
    "    \"\"\"Fetches an image from S3 and returns a numpy array.\"\"\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = response[\"Body\"]\n",
    "    data = body.read()\n",
    "    f = BytesIO(data)\n",
    "    image = Image.open(f)\n",
    "    image_data = np.asarray(image)\n",
    "    return image_data\n",
    "\n",
    "\n",
    "def fetch_image_from_s3(bucket, key):\n",
    "    \"\"\"Fetches an image from S3\"\"\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = response[\"Body\"]\n",
    "    data = body.read()\n",
    "    f = BytesIO(data)\n",
    "    image = Image.open(f)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'geckodriver' executable needs to be in PATH. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/matsy007/.local/lib/python3.6/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'geckodriver': 'geckodriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-402a460012dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# blocked by Instagram. If delay=5 for example, then the browser will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# randomly wait between 0 to 5 seconds before grabbing each new image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscrape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_to_scrape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a6c8b903998a>\u001b[0m in \u001b[0;36mscrape_data\u001b[0;34m(hashtags, n, delay)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mDownload\u001b[0m \u001b[0mn\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFirefox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#print(hashtags)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matsy007/.local/lib/python3.6/site-packages/selenium/webdriver/firefox/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, firefox_profile, firefox_binary, timeout, capabilities, proxy, executable_path, options, service_log_path, firefox_options, service_args, desired_capabilities, log_path, keep_alive)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 log_path=service_log_path)\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_capabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matsy007/.local/lib/python3.6/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'geckodriver' executable needs to be in PATH. \n"
     ]
    }
   ],
   "source": [
    "# \"delay\" is how long to wait between grabbing each image, to avoid being \n",
    "# blocked by Instagram. If delay=5 for example, then the browser will \n",
    "# randomly wait between 0 to 5 seconds before grabbing each new image.\n",
    "scrape_data(hashtags, num_to_scrape, delay=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use `pd.read_json` to import hashtag data again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# travel_df = pd.read_json(\"metadata/travel.json\")\n",
    "# travel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally you can also use this scaffolding for uploading scraped images to an S3 bucket, although you will of course need to set up your own S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# s3 = boto3.resource(\"s3\")\n",
    "\n",
    "# hashtags_to_upload = [\"foo\", \"bar\"]\n",
    "# for hashtag in hashtags_to_upload:\n",
    "#     for img in hashtag: \n",
    "#         source = f\"data/{img[\"image_local_name\"]}\"\n",
    "#         bucket = f\"instagram-images-mod4\"\n",
    "#         destination = f\"{img[\"search_hashtag\"]}/{img[\"image_local_name\"]}\"\n",
    "#         s3.meta.client.upload_file(source, bucket, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FirefoxWebElement' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-ebed51a82406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# to identify element and obtain innerHTML with get_attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HTML code of element: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'innerHTML'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FirefoxWebElement' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# implicit wait applied\n",
    "browser = Firefox()\n",
    "browser.get(\"https://www.instagram.com/p/CcbZMGpPpic/\")\n",
    "# to identify element and obtain innerHTML with get_attribute\n",
    "l = browser.find_element_by_css_selector(\"span\")\n",
    "for x in l:\n",
    "    print(x.text)\n",
    "print(\"HTML code of element: \" + l.get_attribute('innerHTML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
